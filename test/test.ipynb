{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f87b3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca2c6d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 3\n",
    "L = 8\n",
    "Z = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2a7a937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 8, 5]), torch.Size([3, 1, 5]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_buffer = torch.randn(B,L,Z)\n",
    "i = 1\n",
    "latent_buffer.shape, latent_buffer[:, i : i + 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff737e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 5, 5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill = torch.randn(B, L, Z, Z)\n",
    "probs = F.softmax(skill, dim = -1)\n",
    "# probs.shape #torch.Size([3, 8, 5, 5])\n",
    "        # uniform = tf.ones_like(probs) / probs.shape[-1]\n",
    "        # probs = (1 - self._unimix) * probs + self._unimix * uniform\n",
    "dist = OneHotDist(probs=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "009c6bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "\n",
    "class OneHotDist(torch.nn.Module):\n",
    "    def __init__(self, logits: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            logits: Tensor of shape [B, K, K]\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.logits = logits  # [B, K, K]\n",
    "        assert logits.dim() == 3, \"Expected logits of shape [B, M, K]\"\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            A differentiable one-hot sample of shape [B, M, K]\n",
    "        \"\"\"\n",
    "        B, M, K = self.logits.shape\n",
    "\n",
    "        # Flatten for sampling: [B*M, K]\n",
    "        flat_logits = self.logits.reshape(-1, K)\n",
    "\n",
    "        # Sample indices: [B*M]\n",
    "        indices = Categorical(logits=flat_logits).sample()\n",
    "\n",
    "        # One-hot encode: [B*M, K]\n",
    "        hard_sample = F.one_hot(indices, num_classes=K).float()\n",
    "\n",
    "        # Reshape back: [B, M, K]\n",
    "        hard_sample = hard_sample.reshape(B, M, K)\n",
    "\n",
    "        # Straight-through estimator:\n",
    "        # Forward: hard one-hot\n",
    "        # Backward: gradient through softmax\n",
    "        probs = F.softmax(self.logits, dim=-1)\n",
    "        return (hard_sample - probs).detach() + probs  # ST-trick\n",
    "\n",
    "    def log_prob(self, one_hot_action: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            one_hot_action: Tensor of shape [B, M, K], one-hot encoded actions\n",
    "\n",
    "        Returns:\n",
    "            log_prob: Tensor of shape [B, M], log probability per categorical\n",
    "        \"\"\"\n",
    "        log_probs = F.log_softmax(self.logits, dim=-1)\n",
    "        return (log_probs * one_hot_action).sum(dim=-1)  # [B, M]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d0881d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 0.]]),\n",
       " tensor([-2.6144, -1.7148, -1.1793, -0.7010, -1.8167, -1.2877, -2.1071, -1.4316]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = torch.randn(2, 8, 8)\n",
    "\n",
    "dist = OneHotDist(logits)\n",
    "skill = dist.sample()  # [2, 8, 8] â€” each is one-hot, differentiable\n",
    "\n",
    "# Compute log-prob if needed\n",
    "logp = dist.log_prob(skill)  # [2, 8]\n",
    "skill[0], logp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcfb780",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'shapoe'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mlogits\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshapoe\u001b[49m\n",
      "\u001b[31mAttributeError\u001b[39m: 'Tensor' object has no attribute 'shapoe'"
     ]
    }
   ],
   "source": [
    "logits = torch.randn(2, 8, 8)\n",
    "logits.shapoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002afebe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
