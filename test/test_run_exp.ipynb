{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium\n",
    "import ale_py\n",
    "import argparse\n",
    "from tensorboardX import SummaryWriter\n",
    "import cv2\n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import colorama\n",
    "import random\n",
    "import json\n",
    "import shutil\n",
    "import pickle\n",
    "import os\n",
    "import wandb\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"/Users/rijulizer/work_space/Thesis/STORM\"))# Dynamically reload the modules to reflect any changes\n",
    "\n",
    "import utils\n",
    "import sub_models.replay_buffer\n",
    "import env_wrapper\n",
    "# import agents\n",
    "import sub_models.director_agents\n",
    "import sub_models.functions_losses\n",
    "import sub_models.world_models\n",
    "import sub_models.constants\n",
    "import train\n",
    "\n",
    "importlib.reload(utils)\n",
    "importlib.reload(sub_models.replay_buffer)\n",
    "importlib.reload(env_wrapper)\n",
    "importlib.reload(sub_models.director_agents)\n",
    "importlib.reload(sub_models.functions_losses)\n",
    "importlib.reload(sub_models.world_models)\n",
    "importlib.reload(sub_models.constants)\n",
    "importlib.reload(train)\n",
    "\n",
    "from utils import seed_np_torch, Logger, load_config\n",
    "from sub_models.replay_buffer import ReplayBuffer\n",
    "from train import (\n",
    "    build_single_env,\n",
    "    build_vec_env,\n",
    "    build_world_model,\n",
    "    build_agent,\n",
    "    train_world_model,\n",
    "    world_model_imagine_data,\n",
    "    joint_train_world_model_agent,\n",
    ")\n",
    "from sub_models.constants import DEVICE\n",
    "print(DEVICE, DEVICE.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WandbLogger:\n",
    "    def __init__(self, run):\n",
    "        self.run = run\n",
    "\n",
    "    def log(self, key, value, step=None):\n",
    "        \"\"\"Log a key-value pair to wandb with optional step.\"\"\"\n",
    "        log_dict = {key: value}\n",
    "        if step is not None:\n",
    "            self.run.log(log_dict, step=step)\n",
    "        else:\n",
    "            self.run.log(log_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mArguments:\u001b[0m\n",
      "\u001b[32m-----------------\u001b[0m\n",
      "\u001b[32mexp_name: \u001b[0mTEM-Transformer_2\n",
      "\u001b[32mseed: \u001b[0m1\n",
      "\u001b[32mconfig_path: \u001b[0m../config_files/STORM.yaml\n",
      "\u001b[32mtrajectory_path: \u001b[0mD_TRAJ/MsPacman.pkl\n",
      "\u001b[32menv_name: \u001b[0mALE/MsPacman-v5\n",
      "\u001b[32m-----------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(DEVICE)\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    \n",
    "class RunParams:\n",
    "    def __init__(self, env_name=\"MsPacman\", exp_name = \"STORM-Transformer\"):\n",
    "        self._env_name = env_name\n",
    "        self.exp_name = exp_name\n",
    "        self.seed = 1\n",
    "        self.config_path = \"../config_files/STORM.yaml\"\n",
    "        self.trajectory_path = f\"D_TRAJ/{self._env_name}.pkl\"\n",
    "        self.env_name = f\"ALE/{self._env_name}-v5\"\n",
    "\n",
    "        self.conf = load_config(self.config_path)\n",
    "        self.print_args()\n",
    "    def print_args(self):\n",
    "        print(colorama.Fore.GREEN + \"Arguments:\" + colorama.Style.RESET_ALL)\n",
    "        print(colorama.Fore.GREEN + \"-----------------\" + colorama.Style.RESET_ALL)\n",
    "        print(colorama.Fore.GREEN + \"exp_name: \" + colorama.Style.RESET_ALL + self.exp_name)\n",
    "        print(colorama.Fore.GREEN + \"seed: \" + colorama.Style.RESET_ALL + str(self.seed))\n",
    "        print(colorama.Fore.GREEN + \"config_path: \" + colorama.Style.RESET_ALL + self.config_path)\n",
    "        print(colorama.Fore.GREEN + \"trajectory_path: \" + colorama.Style.RESET_ALL + self.trajectory_path)\n",
    "        print(colorama.Fore.GREEN + \"env_name: \" + colorama.Style.RESET_ALL + self.env_name)\n",
    "        print(colorama.Fore.GREEN + \"-----------------\" + colorama.Style.RESET_ALL)\n",
    "\n",
    "run_params = RunParams(env_name=\"MsPacman\", exp_name = \"TEM-Transformer_2\")\n",
    "# set seed\n",
    "seed_np_torch(seed=run_params.seed)\n",
    "# tensorboard writer\n",
    "logger = Logger(path=f\"runs/{run_params.exp_name}\")\n",
    "# copy config file\n",
    "# shutil.copy(run_params.config_path, f\"runs/{run_params.exp_name}/config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.10.2+c9d4b19)\n",
      "[Powered by Stella]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World model transformer: StochasticTransformerKVCache\n",
      "World model parameters: 16508547\n",
      "Agent parameters: 5367561\n"
     ]
    }
   ],
   "source": [
    "# Setuop env, models, replay buffer\n",
    "# getting action_dim with dummy env\n",
    "dummy_env = build_single_env(\n",
    "    run_params.env_name, run_params.conf.BasicSettings.ImageSize, seed=0\n",
    ")\n",
    "action_dim = dummy_env.action_space.n\n",
    "\n",
    "# build world model and agent\n",
    "world_model = build_world_model(run_params.conf, action_dim)\n",
    "agent = build_agent(run_params.conf, action_dim)\n",
    "print(f\"World model transformer: {world_model.storm_transformer.__class__.__name__}\")\n",
    "# Log the number of parameters for both models\n",
    "world_model_params = sum(p.numel() for p in world_model.parameters() if p.requires_grad)\n",
    "agent_params = sum(p.numel() for p in agent.parameters() if p.requires_grad)\n",
    "print(f\"World model parameters: {world_model_params}\")\n",
    "print(f\"Agent parameters: {agent_params}\")\n",
    "# Build replay buffer\n",
    "replay_buffer = ReplayBuffer(\n",
    "    num_envs=run_params.conf.JointTrainAgent.NumEnvs,\n",
    "    obs_shape=(run_params.conf.BasicSettings.ImageSize, run_params.conf.BasicSettings.ImageSize, 3),\n",
    "    max_length=run_params.conf.JointTrainAgent.BufferMaxLength,\n",
    "    warmup_length=20,  #FIXME: run_params.conf.JointTrainAgent.BufferWarmUp,\n",
    "    store_on_gpu=run_params.conf.BasicSettings.ReplayBufferOnGPU,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mriju11-mukherjee\u001b[0m (\u001b[33mrm_ai\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/rijulizer/work_space/Thesis/STORM/test/wandb/run-20250517_103514-xv2h551f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rm_ai/Director/runs/xv2h551f' target=\"_blank\">TEM-Transformer_2</a></strong> to <a href='https://wandb.ai/rm_ai/Director' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rm_ai/Director' target=\"_blank\">https://wandb.ai/rm_ai/Director</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rm_ai/Director/runs/xv2h551f' target=\"_blank\">https://wandb.ai/rm_ai/Director/runs/xv2h551f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.10.2+c9d4b19)\n",
      "[Powered by Stella]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current env: \u001b[33mALE/MsPacman-v5\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/80 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSaving model at total steps 0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1/80 [00:00<00:17,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 21/80 [00:09<00:27,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 22/80 [00:19<01:03,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 23/80 [00:28<01:40,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 24/80 [00:37<02:21,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 25/80 [00:46<03:02,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 26/80 [00:55<03:46,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 27/80 [01:03<04:24,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 28/80 [01:12<04:59,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 29/80 [01:20<05:22,  6.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 30/80 [01:28<05:39,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 31/80 [01:38<06:16,  7.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 32/80 [01:48<06:31,  8.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 33/80 [01:56<06:23,  8.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▎     | 34/80 [02:04<06:11,  8.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 35/80 [02:12<06:01,  8.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 36/80 [02:20<05:53,  8.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 37/80 [02:29<06:05,  8.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 38/80 [02:37<05:48,  8.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 39/80 [02:45<05:35,  8.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 40/80 [02:53<05:30,  8.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 41/80 [03:02<05:19,  8.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 42/80 [03:12<05:35,  8.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 43/80 [03:20<05:21,  8.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 44/80 [03:28<05:06,  8.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 45/80 [03:37<04:57,  8.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▊    | 46/80 [03:45<04:45,  8.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 47/80 [03:53<04:38,  8.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 48/80 [04:02<04:32,  8.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 49/80 [04:11<04:24,  8.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 50/80 [04:19<04:12,  8.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 51/80 [04:27<04:02,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 52/80 [04:35<03:52,  8.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 53/80 [04:44<03:46,  8.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 54/80 [04:52<03:39,  8.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 55/80 [05:02<03:35,  8.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 56/80 [05:11<03:29,  8.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 57/80 [05:19<03:18,  8.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▎  | 58/80 [05:27<03:07,  8.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 59/80 [05:35<02:55,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 60/80 [05:43<02:45,  8.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 61/80 [05:52<02:39,  8.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 62/80 [06:00<02:29,  8.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 63/80 [06:08<02:19,  8.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 64/80 [06:16<02:10,  8.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 65/80 [06:25<02:04,  8.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▎ | 66/80 [06:33<01:55,  8.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 67/80 [06:41<01:46,  8.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 68/80 [06:51<01:45,  8.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 69/80 [07:00<01:37,  8.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 70/80 [07:08<01:27,  8.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 71/80 [07:17<01:18,  8.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 72/80 [07:25<01:08,  8.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 73/80 [07:34<00:59,  8.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▎| 74/80 [07:42<00:50,  8.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 75/80 [07:50<00:42,  8.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 76/80 [07:59<00:33,  8.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 77/80 [08:07<00:25,  8.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 78/80 [08:18<00:18,  9.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 79/80 [08:27<00:08,  8.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training World Model...\n",
      "Training Agent...\n",
      "init_imagine_buffer: 64x16@torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [08:36<00:00,  6.46s/it]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Director/goal_VAE_loss</td><td>█████▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>Director/goal_kl_loss</td><td>▁▂▂▂▂▂▁▂▂▃▃▂▃▃▄▄▅▅▄▄▅▅▇▆▅▇▇▇▇▆█▆▅▅▆▅▆▆▅▄</td></tr><tr><td>Director/goal_recon_loss</td><td>█████▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Director/success_manager</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Manager_AC/S</td><td>▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇████████</td></tr><tr><td>Manager_AC/critic_loss</td><td>▂▂▄▃▄▅▅▇▇█▆▄▄▃▂▂▃▄▆▆▇█▆▇█▄▄▃▃▂▄▅▃▆▇▆▆▅▂▁</td></tr><tr><td>Manager_AC/entropy_loss</td><td>▁▃▃▅▆▆██████████████████████████████████</td></tr><tr><td>Manager_AC/norm_ratio</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Manager_AC/policy_loss</td><td>▂▁▁▂▂▄▄▄▄▄▄▃▄▄▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>Manager_AC/total_loss</td><td>▂▂▁▁▃▅▆▅▅▅▃▂▁▂▂▃▄▅▆▆▇█▇█▇▆▆▅▅▅▆▆▇██▇█▇▆▅</td></tr><tr><td>WM/dynamics_loss</td><td>▃▃▄▅▆▇▇▇███████▇▇▆▆▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>WM/dynamics_real_kl_div</td><td>▃▃▃▄▄▆▇▇███████▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>WM/reconstruction_loss</td><td>█▇▇▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>WM/representation_loss</td><td>▃▃▄▄▅▆▇▇▇█████▇▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>WM/representation_real_kl_div</td><td>▃▃▄▄▅▆▇▇▇▇█████▇▇▇▆▆▅▅▅▅▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>WM/reward_loss</td><td>█▇▆▅▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>WM/termination_loss</td><td>█▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>WM/total_loss</td><td>█▇▇▆▆▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Worker_AC/S</td><td>▁▁▁▂▂▃▃▃▃▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>Worker_AC/critic_loss</td><td>▇█▇▇█▆▅▆▅▆▇█▅▇▅▄▂▄▃▃▄▂▃▄▃▃▃▃▂▂▂▄▂▂▃▂▃▁▃▃</td></tr><tr><td>Worker_AC/entropy_loss</td><td>▁▃▃▃▃▃▃▃▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆█████████████▆▆▆</td></tr><tr><td>Worker_AC/norm_ratio</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Worker_AC/policy_loss</td><td>▅▇▇██▅▅▅▄▄▃▁▃▁▃▄▄▄▄▄▄▄▄▄▄▄▃▃▄▃▄▄▄▃▃▃▃▃▃▃</td></tr><tr><td>Worker_AC/total_loss</td><td>█▇█▇███▆▅▅▅▆▆▄▄▃▃▃▃▃▂▃▄▃▃▃▂▃▂▂▃▂▂▂▂▂▂▂▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Agent_params</td><td>5.37e+06</td></tr><tr><td>Director/goal_VAE_loss</td><td>-1003.0647</td></tr><tr><td>Director/goal_kl_loss</td><td>0.29701</td></tr><tr><td>Director/goal_recon_loss</td><td>-1003.0647</td></tr><tr><td>Director/success_manager</td><td>0</td></tr><tr><td>Manager_AC/S</td><td>0.80021</td></tr><tr><td>Manager_AC/critic_loss</td><td>12.82685</td></tr><tr><td>Manager_AC/entropy_loss</td><td>2.0625</td></tr><tr><td>Manager_AC/norm_ratio</td><td>1</td></tr><tr><td>Manager_AC/policy_loss</td><td>1.51226</td></tr><tr><td>Manager_AC/total_loss</td><td>12.37817</td></tr><tr><td>WM/dynamics_loss</td><td>1.70657</td></tr><tr><td>WM/dynamics_real_kl_div</td><td>1.70657</td></tr><tr><td>WM/reconstruction_loss</td><td>643.22131</td></tr><tr><td>WM/representation_loss</td><td>1.70657</td></tr><tr><td>WM/representation_real_kl_div</td><td>1.70657</td></tr><tr><td>WM/reward_loss</td><td>0.09205</td></tr><tr><td>WM/termination_loss</td><td>0.00068</td></tr><tr><td>WM/total_loss</td><td>644.33795</td></tr><tr><td>WM_params</td><td>1.65e+07</td></tr><tr><td>Worker_AC/S</td><td>0.91553</td></tr><tr><td>Worker_AC/critic_loss</td><td>10.69468</td></tr><tr><td>Worker_AC/entropy_loss</td><td>2.1875</td></tr><tr><td>Worker_AC/norm_ratio</td><td>1</td></tr><tr><td>Worker_AC/policy_loss</td><td>-0.11096</td></tr><tr><td>Worker_AC/total_loss</td><td>8.5056</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TEM-Transformer_2</strong> at: <a href='https://wandb.ai/rm_ai/Director/runs/xv2h551f' target=\"_blank\">https://wandb.ai/rm_ai/Director/runs/xv2h551f</a><br> View project at: <a href='https://wandb.ai/rm_ai/Director' target=\"_blank\">https://wandb.ai/rm_ai/Director</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250517_103514-xv2h551f/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize wandb\n",
    "with wandb.init(\n",
    "    project=\"Director\",  # Replace with your project name\n",
    "    name=run_params.exp_name,   # Use the experiment name from RunParam\n",
    "    config = {\n",
    "        \"env_name\": run_params.env_name,\n",
    "        \"seed\": run_params.seed,\n",
    "    }\n",
    ") as run:\n",
    "    # Log the configuration to wandb\n",
    "    run.config.update(run_params.conf)\n",
    "    run.log({\"WM_params\": f\"{world_model_params:.2e}\", \"Agent_params\": f\"{agent_params:.2e}\"})\n",
    "    logger = WandbLogger(run)\n",
    "\n",
    "    metrics = joint_train_world_model_agent(\n",
    "        env_name=run_params.env_name,\n",
    "        num_envs=run_params.conf.JointTrainAgent.NumEnvs,\n",
    "        max_steps=80,\n",
    "        image_size=run_params.conf.BasicSettings.ImageSize,\n",
    "        replay_buffer=replay_buffer,\n",
    "        world_model=world_model,\n",
    "        agent=agent,\n",
    "        train_dynamics_every_steps=1,\n",
    "        train_agent_every_steps=1,\n",
    "        batch_size=64,\n",
    "        demonstration_batch_size=0,\n",
    "        batch_length=16,\n",
    "        imagine_batch_size=64,\n",
    "        imagine_demonstration_batch_size=0,\n",
    "        imagine_context_length=8,\n",
    "        imagine_batch_length=16,\n",
    "        save_every_steps=2500,\n",
    "        seed=run_params.seed,\n",
    "        logger=logger,\n",
    "        args=run_params,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakdown: joint_train_world_model_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current env: \u001b[33mALE/MsPacman-v5\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.10.2+c9d4b19)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "## setup variable names for breakdown\n",
    "env_name=run_params.env_name\n",
    "num_envs=run_params.conf.JointTrainAgent.NumEnvs\n",
    "max_steps=run_params.conf.JointTrainAgent.SampleMaxSteps\n",
    "image_size=run_params.conf.BasicSettings.ImageSize\n",
    "train_dynamics_every_steps=run_params.conf.JointTrainAgent.TrainDynamicsEverySteps\n",
    "train_agent_every_steps=run_params.conf.JointTrainAgent.TrainAgentEverySteps\n",
    "batch_size=3 #FIXME: run_params.conf.JointTrainAgent.BatchSize\n",
    "demonstration_batch_size=(\n",
    "    run_params.conf.JointTrainAgent.DemonstrationBatchSize\n",
    "    if run_params.conf.JointTrainAgent.UseDemonstration\n",
    "    else 0\n",
    ")\n",
    "batch_length=16 #FIXME: run_params.conf.JointTrainAgent.BatchLength\n",
    "imagine_batch_size=run_params.conf.JointTrainAgent.ImagineBatchSize\n",
    "imagine_demonstration_batch_size=(\n",
    "    run_params.conf.JointTrainAgent.ImagineDemonstrationBatchSize\n",
    "    if run_params.conf.JointTrainAgent.UseDemonstration\n",
    "    else 0\n",
    ")\n",
    "imagine_context_length=run_params.conf.JointTrainAgent.ImagineContextLength\n",
    "imagine_batch_length=16 #FIXME: run_params.conf.JointTrainAgent.ImagineBatchLength\n",
    "save_every_steps=run_params.conf.JointTrainAgent.SaveEverySteps\n",
    "seed=run_params.seed\n",
    "args=run_params\n",
    "\n",
    "\n",
    "## Setup env\n",
    "vec_env = build_vec_env(env_name, image_size, num_envs=1, seed=seed)\n",
    "print(\n",
    "    \"Current env: \"\n",
    "    + colorama.Fore.YELLOW\n",
    "    + f\"{env_name}\"\n",
    "    + colorama.Style.RESET_ALL\n",
    ")\n",
    "\n",
    "# reset envs and variables\n",
    "sum_reward = np.zeros(num_envs)\n",
    "current_obs, current_info = vec_env.reset()\n",
    "context_obs = deque(maxlen=16)\n",
    "context_action = deque(maxlen=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample from env part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 173.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replay buffer ready 21\n",
      "Replay buffer ready 22\n",
      "Replay buffer ready 23\n",
      "Replay buffer ready 24\n",
      "Replay buffer ready 25\n",
      "Replay buffer ready 26\n",
      "Replay buffer ready 27\n",
      "Replay buffer ready 28\n",
      "Replay buffer ready 29\n",
      "Replay buffer ready 30\n",
      "Replay buffer ready 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for total_steps in tqdm(range(32)):\n",
    "    # sample part >>>\n",
    "    if replay_buffer.ready:  # ready only after warmpup\n",
    "        print(\"Replay buffer ready\", total_steps)\n",
    "        # WM and Agent are in eval mode\n",
    "        world_model.eval()\n",
    "        agent.eval()\n",
    "        with torch.no_grad():\n",
    "            if len(context_action) == 0:\n",
    "                # this is the case in the first step\n",
    "                action = vec_env.action_space.sample()\n",
    "            else:\n",
    "                context_latent = world_model.encode_obs(\n",
    "                    torch.cat(list(context_obs), dim=1)\n",
    "                )\n",
    "                model_context_action = np.stack(list(context_action), axis=1)\n",
    "                model_context_action = torch.Tensor(model_context_action).to(DEVICE)\n",
    "                prior_flattened_sample, last_dist_feat = (\n",
    "                    world_model.calc_last_dist_feat(\n",
    "                        context_latent, model_context_action\n",
    "                    )\n",
    "                )\n",
    "                latent = torch.cat([prior_flattened_sample, last_dist_feat], dim=-1)\n",
    "                # get the action, goal and skill from the agent\n",
    "                action = agent.sample_as_env_action(latent)\n",
    "        # [B, H, W, C] -> [B, 1, C, H, W] # B=1\n",
    "        context_obs.append(\n",
    "            torch.permute(\n",
    "                torch.tensor(current_obs, device=DEVICE), (0, 3, 1, 2)\n",
    "            ).unsqueeze(1)\n",
    "            / 255\n",
    "        )\n",
    "        context_action.append(action)\n",
    "    else:\n",
    "        # simply sample random action\n",
    "        action = vec_env.action_space.sample()\n",
    "\n",
    "    # Perform action in the env and observe the next state, reward, done, truncated\n",
    "    obs, reward, done, truncated, info = vec_env.step(action)\n",
    "\n",
    "    # Append the transition to the replay buffer\n",
    "    replay_buffer.append(\n",
    "        current_obs, action, reward, np.logical_or(done, info[\"life_loss\"])\n",
    "        )\n",
    "\n",
    "    done_flag = np.logical_or(done, truncated)\n",
    "    if done_flag.any():  # end of episode\n",
    "        for i in range(num_envs):\n",
    "            if done_flag[i]:\n",
    "                sum_reward[i] = 0\n",
    "\n",
    "    # Update current_obs, current_info and sum_reward\n",
    "    sum_reward += reward\n",
    "    current_obs = obs\n",
    "    current_info = info\n",
    "    # <<< sample part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 64, 64, 3), (1,), (1,), (1,), (1,))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.shape, action.shape, reward.shape, done.shape, truncated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_buffer.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually fill the replay buffer goal and skill\n",
    "# goal and skill should ideally be appended in the replay buffer\n",
    "# replay_buffer.buffer[\"goal\"][0:32] = torch.zeros(32,1,1024)\n",
    "# replay_buffer.buffer[\"skill\"][0:32] = torch.zeros(32,1, 8,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train world model part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Train world model part >>>\n",
    "train_world_model_step(\n",
    "    replay_buffer=replay_buffer,\n",
    "    world_model=world_model,\n",
    "    batch_size=batch_size,\n",
    "    demonstration_batch_size=demonstration_batch_size,\n",
    "    batch_length=batch_length,\n",
    "    logger=logger,\n",
    ")\n",
    "##<<< Train world model part\n",
    "## Breakdown of the above code\n",
    "# Sample from replay buffer\n",
    "# buffer_sample = replay_buffer.sample(\n",
    "#     batch_size, demonstration_batch_size, batch_length\n",
    "# )\n",
    "# for key, value in buffer_sample.items():\n",
    "#     print(f\"{key}, Value shape: {value.shape}\")\n",
    "# obs, Value shape: torch.Size([3, 16, 3, 64, 64])\n",
    "# action, Value shape: torch.Size([3, 16])\n",
    "# reward, Value shape: torch.Size([3, 16])\n",
    "# termination, Value shape: torch.Size([3, 16])\n",
    "# goal, Value shape: torch.Size([3, 16])\n",
    "# skill, Value shape: torch.Size([3, 16])\n",
    "# print(f\"Shapes of obs: {obs.shape}, action: {action.shape}, reward: {reward.shape}, termination: {termination.shape}\")\n",
    "\n",
    "## Train world model with the sampled data\n",
    "# world_model.update(buffer_sample[\"obs\"], buffer_sample[\"action\"], buffer_sample[\"reward\"], buffer_sample[\"termination\"], logger=logger)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train agent part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_imagine_buffer: 1024x16@torch.float32\n",
      "Shape of sample: torch.Size([1024, 17, 1024])\n",
      "Shape of hidden: torch.Size([1024, 17, 512])\n",
      "Shape of action: torch.Size([1024, 16])\n",
      "Shape of reward: torch.Size([1024, 16])\n",
      "Shape of termination: torch.Size([1024, 16])\n",
      "Shape of goal: torch.Size([1024, 16, 1024])\n",
      "Shape of skill: torch.Size([1024, 16, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "# Train agent part >>>\n",
    "# print(\"Training Agent...\")\n",
    "log_video = False\n",
    "imagined_rollout = world_model_imagine_data(\n",
    "    replay_buffer=replay_buffer,\n",
    "    world_model=world_model,\n",
    "    agent=agent,\n",
    "    imagine_batch_size=imagine_batch_size,\n",
    "    imagine_demonstration_batch_size=imagine_demonstration_batch_size,\n",
    "    imagine_context_length=imagine_context_length,\n",
    "    imagine_batch_length=imagine_batch_length,\n",
    "    log_video=log_video,\n",
    "    logger=logger,\n",
    ")\n",
    "for k, v  in imagined_rollout.items():\n",
    "    print(f\"Shape of {k}: {v.shape}\")\n",
    "\n",
    "## breakdown : world_model_imagine_data\n",
    "# imagine_batch_size = 3\n",
    "# world_model.eval()\n",
    "# agent.eval()\n",
    "\n",
    "# buffer_sample = replay_buffer.sample(\n",
    "#     imagine_batch_size, imagine_demonstration_batch_size, imagine_context_length\n",
    "# )\n",
    "# print(f\"Buffer sample items:\")\n",
    "# for k, v  in buffer_sample.items():\n",
    "#     print(f\"Shape of {k}: {v.shape}\")\n",
    "\n",
    "# imagined_rollout = world_model.imagine_data(\n",
    "#     agent,\n",
    "#     buffer_sample,\n",
    "#     imagine_batch_size=imagine_batch_size + imagine_demonstration_batch_size,\n",
    "#     imagine_batch_length=imagine_batch_length,\n",
    "#     log_video=log_video,\n",
    "#     logger=logger,\n",
    "# )\n",
    "# print(f\"\\n\\nImagine rollout items:\")\n",
    "# for k, v  in imagined_rollout.items():\n",
    "#     print(f\"{k}: {v.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Imagine rollout items:\n",
      "sample: torch.Size([1024, 16, 1024])\n",
      "hidden: torch.Size([1024, 16, 512])\n",
      "action: torch.Size([1024, 16])\n",
      "reward: torch.Size([1024, 16])\n",
      "termination: torch.Size([1024, 16])\n",
      "goal: torch.Size([1024, 16, 1024])\n",
      "skill: torch.Size([1024, 16, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "# For the sake of testing the code, L=16\n",
    "imagined_rollout[\"sample\"] = imagined_rollout[\"sample\"][:, 0:16]\n",
    "imagined_rollout[\"hidden\"] = imagined_rollout[\"hidden\"][:, 0:16]\n",
    "print(f\"\\n\\nImagine rollout items:\")\n",
    "for k, v  in imagined_rollout.items():\n",
    "    print(f\"{k}: {v.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update agent with imagined data\n",
    "metrics = agent.update(imagined_rollout)\n",
    "# <<< Train agent part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'goal_VAE_loss': -685.745361328125,\n",
      " 'goal_kl_loss': 0.2932986617088318,\n",
      " 'goal_recon_loss': -685.745361328125,\n",
      " 'manager_ActorCritic/S': 0.040681224316358566,\n",
      " 'manager_ActorCritic/critic_loss': 12.936750411987305,\n",
      " 'manager_ActorCritic/entropy_loss': 1.984375,\n",
      " 'manager_ActorCritic/norm_ratio': 1.0,\n",
      " 'manager_ActorCritic/policy_loss': 1.179916501045227,\n",
      " 'manager_ActorCritic/total_loss': 12.233854293823242,\n",
      " 'success_manager': 0.0,\n",
      " 'worker_ActorCritic/S': 0.021855171769857407,\n",
      " 'worker_ActorCritic/critic_loss': 11.247394561767578,\n",
      " 'worker_ActorCritic/entropy_loss': 2.140625,\n",
      " 'worker_ActorCritic/norm_ratio': 1.0,\n",
      " 'worker_ActorCritic/policy_loss': -0.05270551145076752,\n",
      " 'worker_ActorCritic/total_loss': 9.16343879699707}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "# Print the metrics\n",
    "pprint(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
