{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium\n",
    "import ale_py\n",
    "import argparse\n",
    "from tensorboardX import SummaryWriter\n",
    "import cv2\n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import colorama\n",
    "import random\n",
    "import json\n",
    "import shutil\n",
    "import pickle\n",
    "import os\n",
    "import wandb\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1 cuda\n"
     ]
    }
   ],
   "source": [
    "# Dynamically reload the modules to reflect any changes\n",
    "import utils\n",
    "import replay_buffer\n",
    "import env_wrapper\n",
    "import agents\n",
    "import sub_models.functions_losses\n",
    "import sub_models.world_models\n",
    "import sub_models.constants\n",
    "import train\n",
    "\n",
    "importlib.reload(utils)\n",
    "importlib.reload(replay_buffer)\n",
    "importlib.reload(env_wrapper)\n",
    "importlib.reload(agents)\n",
    "importlib.reload(sub_models.functions_losses)\n",
    "importlib.reload(sub_models.world_models)\n",
    "importlib.reload(sub_models.constants)\n",
    "importlib.reload(train)\n",
    "\n",
    "from utils import seed_np_torch, Logger, load_config\n",
    "from replay_buffer import ReplayBuffer\n",
    "from train import (\n",
    "    build_single_env,\n",
    "    build_vec_env,\n",
    "    build_world_model,\n",
    "    build_agent,\n",
    "    train_world_model_step,\n",
    "    world_model_imagine_data,\n",
    "    joint_train_world_model_agent,\n",
    ")\n",
    "from sub_models.constants import DEVICE\n",
    "print(DEVICE, DEVICE.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(DEVICE)\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WandbLogger:\n",
    "    def __init__(self, run):\n",
    "        self.run = run\n",
    "\n",
    "    def log(self, key, value, step=None):\n",
    "        \"\"\"Log a key-value pair to wandb with optional step.\"\"\"\n",
    "        log_dict = {key: value}\n",
    "        if step is not None:\n",
    "            self.run.log(log_dict, step=step)\n",
    "        else:\n",
    "            self.run.log(log_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mArguments:\u001b[0m\n",
      "\u001b[32m-----------------\u001b[0m\n",
      "\u001b[32mexp_name: \u001b[0mTEM-Transformer_1\n",
      "\u001b[32mseed: \u001b[0m1\n",
      "\u001b[32mconfig_path: \u001b[0mconfig_files/STORM.yaml\n",
      "\u001b[32mtrajectory_path: \u001b[0mD_TRAJ/MsPacman.pkl\n",
      "\u001b[32menv_name: \u001b[0mALE/MsPacman-v5\n",
      "\u001b[32m-----------------\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'runs/TEM-Transformer_1/config.yaml'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class RunParams:\n",
    "    def __init__(self, env_name=\"MsPacman\", exp_name = \"TEM-Transformer\"):\n",
    "        self._env_name = env_name\n",
    "        self.exp_name = exp_name\n",
    "        self.seed = 1\n",
    "        self.config_path = \"config_files/STORM.yaml\"\n",
    "        self.trajectory_path = f\"D_TRAJ/{self._env_name}.pkl\"\n",
    "        self.env_name = f\"ALE/{self._env_name}-v5\"\n",
    "\n",
    "        self.conf = load_config(self.config_path)\n",
    "        self.print_args()\n",
    "    def print_args(self):\n",
    "        print(colorama.Fore.GREEN + \"Arguments:\" + colorama.Style.RESET_ALL)\n",
    "        print(colorama.Fore.GREEN + \"-----------------\" + colorama.Style.RESET_ALL)\n",
    "        print(colorama.Fore.GREEN + \"exp_name: \" + colorama.Style.RESET_ALL + self.exp_name)\n",
    "        print(colorama.Fore.GREEN + \"seed: \" + colorama.Style.RESET_ALL + str(self.seed))\n",
    "        print(colorama.Fore.GREEN + \"config_path: \" + colorama.Style.RESET_ALL + self.config_path)\n",
    "        print(colorama.Fore.GREEN + \"trajectory_path: \" + colorama.Style.RESET_ALL + self.trajectory_path)\n",
    "        print(colorama.Fore.GREEN + \"env_name: \" + colorama.Style.RESET_ALL + self.env_name)\n",
    "        print(colorama.Fore.GREEN + \"-----------------\" + colorama.Style.RESET_ALL)\n",
    "    \n",
    "    # def get_configs(self):\n",
    "        \n",
    "    #     config_dict = {\n",
    "    #         \"env_ImageSize\": self.conf[\"BasicSettings\"][\"ImageSize\"],\n",
    "    #         \"env_ReplayBufferOnGPU\": self.conf[\"BasicSettings\"][\"ReplayBufferOnGPU\"],\n",
    "    #         \"WM_InChannels\": self.conf[\"Models\"][\"WorldModel\"][\"InChannels\"],\n",
    "    #         \"WM_TransformerMaxLength\": self.conf[\"Models\"][\"WorldModel\"][\"TransformerMaxLength\"],\n",
    "    #         \"WM_TransformerHiddenDim\": self.conf[\"Models\"][\"WorldModel\"][\"TransformerHiddenDim\"],\n",
    "    #         \"WM_TransformerNumLayers\": self.conf[\"Models\"][\"WorldModel\"][\"TransformerNumLayers\"],\n",
    "    #         \"WM_TransformerNumHeads\": self.conf[\"Models\"][\"WorldModel\"][\"TransformerNumHeads\"],\n",
    "    #         \"Agent_NumLayers\": self.conf[\"Models\"][\"Agent\"][\"NumLayers\"],\n",
    "    #         \"Agent_HiddenDim\": self.conf[\"Models\"][\"Agent\"][\"HiddenDim\"],\n",
    "    #         \"Agent_Gamma\": self.conf[\"Models\"][\"Agent\"][\"Gamma\"],\n",
    "    #         \"Agent_Lambda\": self.conf[\"Models\"][\"Agent\"][\"Lambda\"],\n",
    "    #         \"Agent_EntropyCoef\": self.conf[\"Models\"][\"Agent\"][\"EntropyCoef\"],\n",
    "    #         \"Train_MaxSteps\": self.conf[\"JointTrainAgent\"][\"SampleMaxSteps\"],\n",
    "    #         \"Train_BufferMaxLength\": self.conf[\"JointTrainAgent\"][\"BufferMaxLength\"],\n",
    "    #         \"Train_BufferWarmUp\": self.conf[\"JointTrainAgent\"][\"BufferWarmUp\"],\n",
    "    #         \"Train_NumEnvs\": self.conf[\"JointTrainAgent\"][\"NumEnvs\"],\n",
    "    #         \"Train_BatchSize\": self.conf[\"JointTrainAgent\"][\"BatchSize\"],\n",
    "    #         \"Train_DemonstrationBatchSize\": self.conf[\"JointTrainAgent\"][\"DemonstrationBatchSize\"],\n",
    "    #         \"Train_BatchLength\": self.conf[\"JointTrainAgent\"][\"BatchLength\"],\n",
    "    #         \"Train_ImagineBatchSize\": self.conf[\"JointTrainAgent\"][\"ImagineBatchSize\"],\n",
    "    #         \"Train_ImagineDemonstrationBatchSize\": self.conf[\"JointTrainAgent\"][\"ImagineDemonstrationBatchSize\"],\n",
    "    #         \"Train_ImagineContextLength\": self.conf[\"JointTrainAgent\"][\"ImagineContextLength\"],\n",
    "    #         \"Train_ImagineBatchLength\": self.conf[\"JointTrainAgent\"][\"ImagineBatchLength\"],\n",
    "    #         \"Train_TrainDynamicsEverySteps\": self.conf[\"JointTrainAgent\"][\"TrainDynamicsEverySteps\"],\n",
    "    #         \"Train_TrainAgentEverySteps\": self.conf[\"JointTrainAgent\"][\"TrainAgentEverySteps\"],\n",
    "    #         \"Train_SaveEverySteps\": self.conf[\"JointTrainAgent\"][\"SaveEverySteps\"],\n",
    "    #         \"Train_UseDemonstration\": self.conf[\"JointTrainAgent\"][\"UseDemonstration\"],\n",
    "    #     }\n",
    "    #     return config_dict\n",
    "\n",
    "run_params = RunParams(env_name=\"MsPacman\", exp_name = \"TEM-Transformer_1\")\n",
    "# set seed\n",
    "seed_np_torch(seed=run_params.seed)\n",
    "# tensorboard writer\n",
    "logger = Logger(path=f\"runs/{run_params.exp_name}\")\n",
    "# copy config file\n",
    "shutil.copy(run_params.config_path, f\"runs/{run_params.exp_name}/config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Steps: 15000\n",
      "Train Batch Size: 256\n",
      "Train Buffer Max Length: 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.10.2+c9d4b19)\n",
      "[Powered by Stella]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World model transformer: TEMTransformerKVCache\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Steps: {run_params.conf.JointTrainAgent.SampleMaxSteps}\")\n",
    "print(f\"Train Batch Size: {run_params.conf.JointTrainAgent.BatchSize}\")\n",
    "print(f\"Train Buffer Max Length: {run_params.conf.JointTrainAgent.BufferMaxLength}\")\n",
    "# Setuop env, models, replay buffer\n",
    "# getting action_dim with dummy env\n",
    "dummy_env = build_single_env(\n",
    "    run_params.env_name, run_params.conf.BasicSettings.ImageSize, seed=0\n",
    ")\n",
    "action_dim = dummy_env.action_space.n\n",
    "\n",
    "# build world model and agent\n",
    "world_model = build_world_model(run_params.conf, action_dim)\n",
    "agent = build_agent(run_params.conf, action_dim)\n",
    "print(f\"World model transformer: {world_model.storm_transformer.__class__.__name__}\")\n",
    "# Log the number of parameters for both models\n",
    "world_model_params = sum(p.numel() for p in world_model.parameters() if p.requires_grad)\n",
    "agent_params = sum(p.numel() for p in agent.parameters() if p.requires_grad)\n",
    "\n",
    "# build replay buffer\n",
    "replay_buffer = ReplayBuffer(\n",
    "    obs_shape=(run_params.conf.BasicSettings.ImageSize, run_params.conf.BasicSettings.ImageSize, 3),\n",
    "    num_envs=run_params.conf.JointTrainAgent.NumEnvs,\n",
    "    max_length=run_params.conf.JointTrainAgent.BufferMaxLength,\n",
    "    warmup_length=run_params.conf.JointTrainAgent.BufferWarmUp,\n",
    "    store_on_gpu=run_params.conf.BasicSettings.ReplayBufferOnGPU,\n",
    ")\n",
    "# judge whether to load demonstration trajectory\n",
    "if run_params.conf.JointTrainAgent.UseDemonstration:\n",
    "    print(\n",
    "        colorama.Fore.MAGENTA\n",
    "        + f\"loading demonstration trajectory from {run_params.trajectory_path}\"\n",
    "        + colorama.Style.RESET_ALL\n",
    "    )\n",
    "    replay_buffer.load_trajectory(path=run_params.trajectory_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mriju11-mukherjee\u001b[0m (\u001b[33mrm_ai\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/I6347325/work_space/STORM/wandb/run-20250406_155037-5a8u907f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rm_ai/WMBRL/runs/5a8u907f' target=\"_blank\">TEM-Transformer_1</a></strong> to <a href='https://wandb.ai/rm_ai/WMBRL' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rm_ai/WMBRL' target=\"_blank\">https://wandb.ai/rm_ai/WMBRL</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rm_ai/WMBRL/runs/5a8u907f' target=\"_blank\">https://wandb.ai/rm_ai/WMBRL/runs/5a8u907f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current env: \u001b[33mALE/MsPacman-v5\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSaving model at total steps 0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 931/15000 [00:01<00:16, 870.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_imagine_buffer: 1024x16@torch.float16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1155/15000 [01:39<2:22:26,  1.62it/s]"
     ]
    }
   ],
   "source": [
    "# Initialize wandb\n",
    "with wandb.init(\n",
    "    project=\"WMBRL\",  # Replace with your project name\n",
    "    name=run_params.exp_name,   # Use the experiment name from RunParam\n",
    "    config = {\n",
    "        \"env_name\": run_params.env_name,\n",
    "        \"seed\": run_params.seed,\n",
    "    }\n",
    ") as run:\n",
    "    # Log the configuration to wandb\n",
    "    run.config.update(run_params.conf)\n",
    "    run.log({\"WM_params\": f\"{world_model_params:.2e}\", \"Agent_params\": f\"{agent_params:.2e}\"})\n",
    "    logger = WandbLogger(run)\n",
    "    # train\n",
    "    joint_train_world_model_agent(\n",
    "        env_name=run_params.env_name,\n",
    "        num_envs=run_params.conf.JointTrainAgent.NumEnvs,\n",
    "        max_steps=run_params.conf.JointTrainAgent.SampleMaxSteps,\n",
    "        image_size=run_params.conf.BasicSettings.ImageSize,\n",
    "        replay_buffer=replay_buffer,\n",
    "        world_model=world_model,\n",
    "        agent=agent,\n",
    "        train_dynamics_every_steps=run_params.conf.JointTrainAgent.TrainDynamicsEverySteps,\n",
    "        train_agent_every_steps=run_params.conf.JointTrainAgent.TrainAgentEverySteps,\n",
    "        batch_size=run_params.conf.JointTrainAgent.BatchSize,\n",
    "        demonstration_batch_size=(\n",
    "            run_params.conf.JointTrainAgent.DemonstrationBatchSize\n",
    "            if run_params.conf.JointTrainAgent.UseDemonstration\n",
    "            else 0\n",
    "        ),\n",
    "        batch_length=run_params.conf.JointTrainAgent.BatchLength,\n",
    "        imagine_batch_size=run_params.conf.JointTrainAgent.ImagineBatchSize,\n",
    "        imagine_demonstration_batch_size=(\n",
    "            run_params.conf.JointTrainAgent.ImagineDemonstrationBatchSize\n",
    "            if run_params.conf.JointTrainAgent.UseDemonstration\n",
    "            else 0\n",
    "        ),\n",
    "        imagine_context_length=run_params.conf.JointTrainAgent.ImagineContextLength,\n",
    "        imagine_batch_length=run_params.conf.JointTrainAgent.ImagineBatchLength,\n",
    "        save_every_steps=run_params.conf.JointTrainAgent.SaveEverySteps,\n",
    "        seed=run_params.seed,\n",
    "        logger=logger,\n",
    "        args=run_params,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
