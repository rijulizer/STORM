{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium\n",
    "import ale_py\n",
    "import argparse\n",
    "from tensorboardX import SummaryWriter\n",
    "import cv2\n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import colorama\n",
    "import random\n",
    "import json\n",
    "import shutil\n",
    "import pickle\n",
    "import os\n",
    "import wandb\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/I6347325/miniconda3/envs/env_RL/lib/python3.13/site-packages/torchrl/data/replay_buffers/samplers.py:34: UserWarning: Failed to import torchrl C++ binaries. Some modules (eg, prioritized replay buffers) may not work with your installation. This is likely due to a discrepancy between your package version and the PyTorch version. Make sure both are compatible. Usually, torchrl majors follow the pytorch majors within a few days around the release. For instance, TorchRL 0.5 requires PyTorch 2.4.0, and TorchRL 0.6 requires PyTorch 2.5.0.\n",
      "  warnings.warn(EXTENSION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1 cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.abspath(\"/data/I6347325/work_space/STORM\"))# Dynamically reload the modules to reflect any changes\n",
    "\n",
    "import utils\n",
    "import sub_models.replay_buffer\n",
    "import env_wrapper\n",
    "# import agents\n",
    "import sub_models.director_agents\n",
    "import sub_models.functions_losses\n",
    "import sub_models.world_models\n",
    "import sub_models.constants\n",
    "import train\n",
    "\n",
    "importlib.reload(utils)\n",
    "importlib.reload(sub_models.replay_buffer)\n",
    "importlib.reload(env_wrapper)\n",
    "importlib.reload(sub_models.director_agents)\n",
    "importlib.reload(sub_models.functions_losses)\n",
    "importlib.reload(sub_models.world_models)\n",
    "importlib.reload(sub_models.constants)\n",
    "importlib.reload(train)\n",
    "\n",
    "from utils import seed_np_torch, Logger, load_config\n",
    "from sub_models.replay_buffer import ReplayBuffer\n",
    "from train import (\n",
    "    build_single_env,\n",
    "    build_world_model,\n",
    "    build_agent,\n",
    "    joint_train_world_model_agent,\n",
    ")\n",
    "from sub_models.constants import DEVICE\n",
    "print(DEVICE, DEVICE.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(DEVICE)\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(DEVICE)\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "class WandbLogger:\n",
    "    def __init__(self, run):\n",
    "        self.run = run\n",
    "\n",
    "    def log(self, key, value, step=None):\n",
    "        \"\"\"Log a key-value pair to wandb with optional step.\"\"\"\n",
    "        log_dict = {key: value}\n",
    "        if step is not None:\n",
    "            self.run.log(log_dict, step=step)\n",
    "        else:\n",
    "            self.run.log(log_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mArguments:\u001b[0m\n",
      "\u001b[32m-----------------\u001b[0m\n",
      "\u001b[32mexp_name: \u001b[0mMultiEnv-Baseline\n",
      "\u001b[32mseed: \u001b[0m1\n",
      "\u001b[32menv_name: \u001b[0m\n",
      "['MiniGrid-Empty-8x8-v0', 'MiniGrid-SimpleCrossingS9N3-v0', 'MiniGrid-FourRooms-v0']\n",
      "\u001b[32m-----------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "class RunParams:\n",
    "    def __init__(self, env_names, exp_name: str):\n",
    "        # self._env_name = env_name\n",
    "        self.exp_name = exp_name\n",
    "        self.seed = 1\n",
    "        self.config_path = \"config_files/STORM.yaml\"\n",
    "        # self.trajectory_path = f\"D_TRAJ/{self._env_name}.pkl\"\n",
    "        self.env_names = env_names\n",
    "\n",
    "        self.conf = load_config(self.config_path)\n",
    "        self.print_args()\n",
    "    def print_args(self):\n",
    "        print(colorama.Fore.GREEN + \"Arguments:\" + colorama.Style.RESET_ALL)\n",
    "        print(colorama.Fore.GREEN + \"-----------------\" + colorama.Style.RESET_ALL)\n",
    "        print(colorama.Fore.GREEN + \"exp_name: \" + colorama.Style.RESET_ALL + self.exp_name)\n",
    "        print(colorama.Fore.GREEN + \"seed: \" + colorama.Style.RESET_ALL + str(self.seed))\n",
    "        # print(colorama.Fore.GREEN + \"config_path: \" + colorama.Style.RESET_ALL + self.config_path)\n",
    "        print(colorama.Fore.GREEN + \"env_name: \" + colorama.Style.RESET_ALL)\n",
    "        print(self.env_names)\n",
    "        print(colorama.Fore.GREEN + \"-----------------\" + colorama.Style.RESET_ALL)\n",
    "\n",
    "env_names = [\n",
    "    \"MiniGrid-Empty-8x8-v0\", \n",
    "    \"MiniGrid-SimpleCrossingS9N3-v0\", \n",
    "    # \"MiniGrid-DoorKey-8x8-v0\", \n",
    "    \"MiniGrid-FourRooms-v0\",\n",
    "    ] \n",
    "run_params = RunParams(env_names, exp_name = \"MultiEnv-Baseline\")\n",
    "# set seed\n",
    "seed_np_torch(seed=run_params.seed)\n",
    "# tensorboard writer\n",
    "logger = Logger(path=f\"runs/{run_params.exp_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Steps: 50000\n",
      "Train Batch Size: 128\n",
      "Train Buffer Max Length: 100000\n",
      "Number of Environments: 3\n",
      "World model transformer: StochasticTransformerKVCache\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Steps: {run_params.conf.JointTrainAgent.SampleMaxSteps}\")\n",
    "print(f\"Train Batch Size: {run_params.conf.JointTrainAgent.BatchSize}\")\n",
    "print(f\"Train Buffer Max Length: {run_params.conf.JointTrainAgent.BufferMaxLength}\")\n",
    "print(f\"Number of Environments: {len(run_params.env_names)}\")\n",
    "# Setuop env, models, replay buffer\n",
    "# getting action_dim with dummy env\n",
    "dummy_env = build_single_env(\n",
    "    run_params.env_names[0], run_params.conf.BasicSettings.ImageSize)\n",
    "action_dim = dummy_env.action_space.n\n",
    "\n",
    "# build world model and agent\n",
    "world_model = build_world_model(run_params.conf, action_dim)\n",
    "agent = build_agent(run_params.conf, action_dim)\n",
    "print(f\"World model transformer: {world_model.storm_transformer.__class__.__name__}\")\n",
    "# Log the number of parameters for both models\n",
    "world_model_params = sum(p.numel() for p in world_model.parameters() if p.requires_grad)\n",
    "agent_params = sum(p.numel() for p in agent.parameters() if p.requires_grad)\n",
    "\n",
    "# build replay buffer\n",
    "replay_buffer = ReplayBuffer(\n",
    "    obs_shape=(run_params.conf.BasicSettings.ImageSize, run_params.conf.BasicSettings.ImageSize, 3),\n",
    "    num_envs=len(run_params.env_names),\n",
    "    max_length=run_params.conf.JointTrainAgent.BufferMaxLength,\n",
    "    warmup_length=run_params.conf.JointTrainAgent.BufferWarmUp,\n",
    "    store_on_gpu=run_params.conf.BasicSettings.ReplayBufferOnGPU,\n",
    ")\n",
    "# judge whether to load demonstration trajectory\n",
    "if run_params.conf.JointTrainAgent.UseDemonstration:\n",
    "    print(\n",
    "        colorama.Fore.MAGENTA\n",
    "        + f\"loading demonstration trajectory from {run_params.trajectory_path}\"\n",
    "        + colorama.Style.RESET_ALL\n",
    "    )\n",
    "    replay_buffer.load_trajectory(path=run_params.trajectory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/I6347325/miniconda3/envs/env_RL/lib/python3.13/site-packages/torchrl/data/replay_buffers/samplers.py:34: UserWarning: Failed to import torchrl C++ binaries. Some modules (eg, prioritized replay buffers) may not work with your installation. This is likely due to a discrepancy between your package version and the PyTorch version. Make sure both are compatible. Usually, torchrl majors follow the pytorch majors within a few days around the release. For instance, TorchRL 0.5 requires PyTorch 2.4.0, and TorchRL 0.6 requires PyTorch 2.5.0.\n",
      "  warnings.warn(EXTENSION_WARNING)\n",
      "/home/I6347325/miniconda3/envs/env_RL/lib/python3.13/site-packages/torchrl/data/replay_buffers/samplers.py:34: UserWarning: Failed to import torchrl C++ binaries. Some modules (eg, prioritized replay buffers) may not work with your installation. This is likely due to a discrepancy between your package version and the PyTorch version. Make sure both are compatible. Usually, torchrl majors follow the pytorch majors within a few days around the release. For instance, TorchRL 0.5 requires PyTorch 2.4.0, and TorchRL 0.6 requires PyTorch 2.5.0.\n",
      "  warnings.warn(EXTENSION_WARNING)\n",
      "/home/I6347325/miniconda3/envs/env_RL/lib/python3.13/site-packages/torchrl/data/replay_buffers/samplers.py:34: UserWarning: Failed to import torchrl C++ binaries. Some modules (eg, prioritized replay buffers) may not work with your installation. This is likely due to a discrepancy between your package version and the PyTorch version. Make sure both are compatible. Usually, torchrl majors follow the pytorch majors within a few days around the release. For instance, TorchRL 0.5 requires PyTorch 2.4.0, and TorchRL 0.6 requires PyTorch 2.5.0.\n",
      "  warnings.warn(EXTENSION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current env: \u001b[33m3 parallel envs\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSaving model at total steps 0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 341/50000 [00:01<03:51, 214.94it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 1024 but got size 1023 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m logger = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# train\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43mjoint_train_world_model_agent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43menv_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43menv_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_envs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrun_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43menv_names\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mJointTrainAgent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSampleMaxSteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mBasicSettings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mImageSize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreplay_buffer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreplay_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mworld_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mworld_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[43m=\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dynamics_every_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_agent_every_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mJointTrainAgent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mBatchSize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdemonstration_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mJointTrainAgent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDemonstrationBatchSize\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mJointTrainAgent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mUseDemonstration\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mJointTrainAgent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mBatchLength\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimagine_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mJointTrainAgent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mImagineBatchSize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimagine_demonstration_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mJointTrainAgent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mImagineDemonstrationBatchSize\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mJointTrainAgent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mUseDemonstration\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimagine_context_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mJointTrainAgent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mImagineContextLength\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimagine_batch_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mJointTrainAgent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mImagineBatchLength\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_every_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mJointTrainAgent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSaveEverySteps\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/I6347325/work_space/STORM/train.py:303\u001b[39m, in \u001b[36mjoint_train_world_model_agent\u001b[39m\u001b[34m(env_names, max_steps, num_envs, image_size, replay_buffer, world_model, agent, train_dynamics_every_steps, train_agent_every_steps, batch_size, demonstration_batch_size, batch_length, imagine_batch_size, imagine_demonstration_batch_size, imagine_context_length, imagine_batch_length, save_every_steps, seed, logger, args)\u001b[39m\n\u001b[32m    301\u001b[39m log_video = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    302\u001b[39m \u001b[38;5;66;03m# Generate imagined rollout data\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m303\u001b[39m imagine_rollout = \u001b[43mworld_model_imagine_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    304\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreplay_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    305\u001b[39m \u001b[43m    \u001b[49m\u001b[43mworld_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimagine_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimagine_demonstration_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimagine_context_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimagine_batch_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_video\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# logger,\u001b[39;49;00m\n\u001b[32m    313\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[38;5;66;03m# Update agent with imagined data\u001b[39;00m\n\u001b[32m    315\u001b[39m agent_metrics = agent.update(imagine_rollout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/env_RL/lib/python3.13/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/I6347325/work_space/STORM/train.py:152\u001b[39m, in \u001b[36mworld_model_imagine_data\u001b[39m\u001b[34m(replay_buffer, world_model, agent, imagine_batch_size, imagine_demonstration_batch_size, imagine_context_length, imagine_batch_length, log_video, logger)\u001b[39m\n\u001b[32m    146\u001b[39m buffer_sample = replay_buffer.sample(\n\u001b[32m    147\u001b[39m     imagine_batch_size, imagine_demonstration_batch_size, imagine_context_length\n\u001b[32m    148\u001b[39m )\n\u001b[32m    149\u001b[39m \u001b[38;5;66;03m# Buffer sample items:\u001b[39;00m\n\u001b[32m    150\u001b[39m \u001b[38;5;66;03m# obs: ([B, L, 3, 64, 64]); action: ([B, L]); reward: ([B, L]); termination: ([B, L])\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m imagined_rollout = \u001b[43mworld_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimagine_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbuffer_sample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimagine_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimagine_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mimagine_demonstration_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimagine_batch_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimagine_batch_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_video\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_video\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[38;5;66;03m# Imagine rollout items:\u001b[39;00m\n\u001b[32m    161\u001b[39m \u001b[38;5;66;03m# sample: ([B, L+1, 1024]); hidden: ([B, L+1, 512])\u001b[39;00m\n\u001b[32m    162\u001b[39m \u001b[38;5;66;03m# action: ([B, L]); reward: ([B, L]); termination: ([B, L])\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[38;5;66;03m# goal: ([B, L, 1024]); skill: ([B, L, 8, 8])\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m imagined_rollout\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/I6347325/work_space/STORM/sub_models/world_models.py:485\u001b[39m, in \u001b[36mWorldModel.imagine_data\u001b[39m\u001b[34m(self, agent, buffer_sample, imagine_batch_size, imagine_batch_length, log_video, logger)\u001b[39m\n\u001b[32m    477\u001b[39m \u001b[38;5;66;03m# initiate the buffer with the first sample\u001b[39;00m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(buffer_sample[\u001b[33m\"\u001b[39m\u001b[33mobs\u001b[39m\u001b[33m\"\u001b[39m].shape[\u001b[32m1\u001b[39m]):\n\u001b[32m    479\u001b[39m     (\n\u001b[32m    480\u001b[39m         last_obs_hat,\n\u001b[32m    481\u001b[39m         last_reward_hat,\n\u001b[32m    482\u001b[39m         last_termination_hat,\n\u001b[32m    483\u001b[39m         last_flattened_sample,\n\u001b[32m    484\u001b[39m         last_dist_feat,\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext_latent\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbuffer_sample\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog_video\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_video\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[38;5;28mself\u001b[39m.sample_buffer[:, \u001b[32m0\u001b[39m:\u001b[32m1\u001b[39m] = last_flattened_sample\n\u001b[32m    491\u001b[39m \u001b[38;5;28mself\u001b[39m.hidden_buffer[:, \u001b[32m0\u001b[39m:\u001b[32m1\u001b[39m] = last_dist_feat\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/I6347325/work_space/STORM/sub_models/world_models.py:386\u001b[39m, in \u001b[36mWorldModel.predict_next\u001b[39m\u001b[34m(self, last_flattened_sample, action, log_video)\u001b[39m\n\u001b[32m    378\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    379\u001b[39m \u001b[33;03mA single step of world model prediction in the imagination phase.\u001b[39;00m\n\u001b[32m    380\u001b[39m \u001b[33;03mFor the WM, only sample and action are required to predict the next token.\u001b[39;00m\n\u001b[32m    381\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    382\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.autocast(\n\u001b[32m    383\u001b[39m     device_type=DEVICE.type, dtype=DTYPE_16, enabled=\u001b[38;5;28mself\u001b[39m.use_amp\n\u001b[32m    384\u001b[39m ):\n\u001b[32m    385\u001b[39m     \u001b[38;5;66;03m# posterior_logits sample + action -> trasnformer hidden states\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m     trans_feat = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorm_transformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward_with_kv_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlast_flattened_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    389\u001b[39m     \u001b[38;5;66;03m# trasnformer hidden states -> prior_logits\u001b[39;00m\n\u001b[32m    390\u001b[39m     prior_logits = \u001b[38;5;28mself\u001b[39m.dist_head.forward_prior(trans_feat)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/I6347325/work_space/STORM/sub_models/transformer_model.py:276\u001b[39m, in \u001b[36mStochasticTransformerKVCache.forward_with_kv_cache\u001b[39m\u001b[34m(self, samples, action)\u001b[39m\n\u001b[32m    273\u001b[39m feats = \u001b[38;5;28mself\u001b[39m.layer_norm(feats)\n\u001b[32m    275\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.layer_stack):\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m     \u001b[38;5;28mself\u001b[39m.kv_cache_list[idx] = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkv_cache_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeats\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    277\u001b[39m     feats, attn = layer(\n\u001b[32m    278\u001b[39m         feats, \u001b[38;5;28mself\u001b[39m.kv_cache_list[idx], \u001b[38;5;28mself\u001b[39m.kv_cache_list[idx], mask\n\u001b[32m    279\u001b[39m     )\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m feats\n",
      "\u001b[31mRuntimeError\u001b[39m: Sizes of tensors must match except in dimension 1. Expected size 1024 but got size 1023 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "# # Initialize wandb\n",
    "# with wandb.init(\n",
    "#     project=\"Thesis\",  # Replace with your project name\n",
    "#     name=run_params.exp_name,   # Use the experiment name from RunParam\n",
    "#     config = {\n",
    "#         # \"env_names\": run_params.env_name,\n",
    "#         \"seed\": run_params.seed,\n",
    "#     }\n",
    "# ) as run:\n",
    "#     # Log the configuration to wandb\n",
    "#     run.config.update(run_params.conf)\n",
    "#     run.log({\"WM_params\": f\"{world_model_params:.2e}\", \"Agent_params\": f\"{agent_params:.2e}\"})\n",
    "#     logger = WandbLogger(run)\n",
    "logger = None\n",
    "\n",
    "# train\n",
    "joint_train_world_model_agent(\n",
    "    env_names=run_params.env_names,\n",
    "    num_envs=len(run_params.env_names),\n",
    "    max_steps=run_params.conf.JointTrainAgent.SampleMaxSteps,\n",
    "    env_observablity=run_params.conf.BasicSettings.EnvObservability,\n",
    "    image_size=run_params.conf.BasicSettings.ImageSize,\n",
    "    replay_buffer=replay_buffer,\n",
    "    world_model=world_model,\n",
    "    agent=agent,\n",
    "    train_dynamics_every_steps=4,\n",
    "    train_agent_every_steps=4,\n",
    "    batch_size=run_params.conf.JointTrainAgent.BatchSize,\n",
    "    demonstration_batch_size=(\n",
    "        run_params.conf.JointTrainAgent.DemonstrationBatchSize\n",
    "        if run_params.conf.JointTrainAgent.UseDemonstration\n",
    "        else 0\n",
    "    ),\n",
    "    batch_length=run_params.conf.JointTrainAgent.BatchLength,\n",
    "    imagine_batch_size=run_params.conf.JointTrainAgent.ImagineBatchSize,\n",
    "    imagine_demonstration_batch_size=(\n",
    "        run_params.conf.JointTrainAgent.ImagineDemonstrationBatchSize\n",
    "        if run_params.conf.JointTrainAgent.UseDemonstration\n",
    "        else 0\n",
    "    ),\n",
    "    imagine_context_length=run_params.conf.JointTrainAgent.ImagineContextLength,\n",
    "    imagine_batch_length=run_params.conf.JointTrainAgent.ImagineBatchLength,\n",
    "    save_every_steps=run_params.conf.JointTrainAgent.SaveEverySteps * 4,\n",
    "    seed=run_params.seed,\n",
    "    logger=logger,\n",
    "    args=run_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
