1. Save the goal and skill from policy_step to replay buffer, imagine rollout
2. Check the distributions of Manager, Worker, 
    Done
3. Check the distributions GoalEncoder and GoalDecoder and corresponding fitting
    Done
4. Check Device, backpropagation and optimization related code

5. context_latent.shape, model_context_action.shape, prior_flattened_sample.shape, last_dist_feat.shape
    (torch.Size([1, 1, 1024]), torch.Size([1, 1]), torch.Size([1, 1, 1024]), torch.Size([1, 1, 512]))

# buffer just holds the data realted to environment;
when that data is loaded. the WM.imagine_data() function converts the environmental data to latent sample, etc....
So the agent related data can also be dealt like that. The agent can store goal and skill. 
Moreoever the stoing is only necesaay withon one contenxt length L

TODOs:
1. Check the losses why are some in negative do they make sense?
2. Inspect sanity if all the things are workign by inspecting them like if the goals are working if the skill is working
3. Track diagonistics data like if the weights are changing or not stuff like that
4. Then think logically if something is not working!!